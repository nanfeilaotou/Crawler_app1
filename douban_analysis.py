"""
è±†ç“£ç”µå½±Top250æ•°æ®åˆ†æç³»ç»Ÿ v2.0
åŠŸèƒ½ï¼šçˆ¬å– -> æ¸…æ´— -> å­˜å‚¨ -> åˆ†æ -> å¯è§†åŒ–
"""

# ========== ã€ç¬¬ä¸€éƒ¨åˆ†ã€‘MATPLOTLIB é…ç½® - å¿…é¡»æ”¾åœ¨æœ€æœ€å¼€å¤´ï¼ ==========
# æ³¨æ„ï¼šmatplotlibçš„é…ç½®éœ€è¦åœ¨å¯¼å…¥å…¶ä»–matplotlibæ¨¡å—ä¹‹å‰å®Œæˆ
import matplotlib

# æ–¹æ¡ˆ1: ä½¿ç”¨ 'Agg' åç«¯ï¼ˆæœ€ç¨³å®šï¼Œç›´æ¥ç”Ÿæˆå›¾ç‰‡æ–‡ä»¶ï¼Œä¸å¼¹çª—ï¼‰
# Aggåç«¯ç”¨äºéäº¤äº’å¼ç¯å¢ƒï¼Œå°†å›¾å½¢æ¸²æŸ“ä¸ºå›¾åƒæ–‡ä»¶
matplotlib.use('Agg')

# æ–¹æ¡ˆ2: å¦‚æœæƒ³å°è¯•å¼¹çª—æ˜¾ç¤ºï¼Œä½†åœ¨PyCharmä¸­å¯èƒ½æœ‰é—®é¢˜
# matplotlib.use('TkAgg')

# è®¾ç½®ä¸­æ–‡å­—ä½“
# æŒ‡å®šä¸­æ–‡å­—ä½“åˆ—è¡¨ï¼Œç¨‹åºä¼šæŒ‰é¡ºåºå°è¯•ä½¿ç”¨è¿™äº›å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'KaiTi']
# è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
matplotlib.rcParams['axes.unicode_minus'] = False
# ================================================================

# ========== ã€ç¬¬äºŒéƒ¨åˆ†ã€‘å…¶ä»–ç¬¬ä¸‰æ–¹åº“å¯¼å…¥ ==========
import requests  # ç”¨äºå‘é€HTTPè¯·æ±‚è·å–ç½‘é¡µå†…å®¹
from bs4 import BeautifulSoup  # ç”¨äºè§£æHTMLæ–‡æ¡£
import pandas as pd  # æ•°æ®å¤„ç†åº“ï¼Œç”¨äºæ•°æ®æ¸…æ´—å’Œåˆ†æ
import sqlite3  # SQLiteæ•°æ®åº“æ“ä½œ
# æ³¨æ„ï¼šè¿™é‡Œå¯¼å…¥çš„æ˜¯ pltï¼Œå®ƒå·²ç»ç»§æ‰¿äº†ä¸Šæ–¹çš„å…¨éƒ¨é…ç½®
import matplotlib.pyplot as plt  # æ•°æ®å¯è§†åŒ–åº“
from wordcloud import WordCloud, STOPWORDS  # è¯äº‘ç”Ÿæˆåº“
import numpy as np  # ç§‘å­¦è®¡ç®—åº“
from datetime import datetime  # æ—¥æœŸæ—¶é—´å¤„ç†
import time  # æ—¶é—´ç›¸å…³åŠŸèƒ½ï¼Œç”¨äºå»¶è¿Ÿ
# ================================================

# ========== ã€ç¬¬ä¸‰éƒ¨åˆ†ã€‘é…ç½®ç±» ==========
class Config:
    """é¡¹ç›®é…ç½®ç±»ï¼Œå­˜å‚¨æ‰€æœ‰é…ç½®å‚æ•°"""
    BASE_URL = 'https://movie.douban.com/top250'  # è±†ç“£ç”µå½±Top250åŸºç¡€URL
    HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',  # æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9',  # æ¥å—ä¸­æ–‡è¯­è¨€
    }
    DB_NAME = 'douban_movies.db'  # SQLiteæ•°æ®åº“æ–‡ä»¶å
    REQUEST_DELAY = 2  # è¯·æ±‚å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé˜²æ­¢è¢«å°IP
    MAX_PAGES = 2  # æµ‹è¯•ç”¨2é¡µï¼Œå®Œæ•´çˆ¬å–æ”¹ä¸º10ï¼ˆæ¯é¡µ25éƒ¨ç”µå½±ï¼Œ10é¡µ=250éƒ¨ï¼‰
# =======================================

# ==================== çˆ¬è™«æ¨¡å— ====================
class DoubanSpider:
    """è±†ç“£çˆ¬è™«æ ¸å¿ƒç±»ï¼Œè´Ÿè´£çˆ¬å–å’Œè§£æè±†ç“£ç”µå½±Top250æ•°æ®"""

    def __init__(self):
        """åˆå§‹åŒ–æ–¹æ³•ï¼Œåˆ›å»ºä¼šè¯å¹¶è®¾ç½®è¯·æ±‚å¤´"""
        self.session = requests.Session()  # åˆ›å»ºæŒä¹…ä¼šè¯
        self.session.headers.update(Config.HEADERS)  # æ›´æ–°ä¼šè¯çš„è¯·æ±‚å¤´

    def fetch_page(self, start=0):
        """
        è·å–å•é¡µæ•°æ®
        startå‚æ•°è¡¨ç¤ºä»ç¬¬å‡ éƒ¨ç”µå½±å¼€å§‹ï¼ˆè±†ç“£çš„åˆ†é¡µå‚æ•°ï¼‰
        è¿”å›HTMLé¡µé¢å†…å®¹æˆ–Noneï¼ˆå¦‚æœè¯·æ±‚å¤±è´¥ï¼‰
        """
        try:
            params = {'start': start, 'filter': ''}  # è¯·æ±‚å‚æ•°
            response = self.session.get(Config.BASE_URL, params=params, timeout=15)  # å‘é€GETè¯·æ±‚
            response.raise_for_status()  # å¦‚æœå“åº”çŠ¶æ€ç ä¸æ˜¯200ï¼ŒæŠ›å‡ºå¼‚å¸¸
            response.encoding = 'utf-8'  # è®¾ç½®ç¼–ç ä¸ºUTF-8
            time.sleep(Config.REQUEST_DELAY)  # å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            return response.text  # è¿”å›HTMLæ–‡æœ¬
        except Exception as e:
            print(f"âŒ è·å–é¡µé¢å¤±è´¥ (start={start}): {e}")
            return None

    @staticmethod
    def parse_movie_item(item):
        """
        è§£æå•ä¸ªç”µå½±æ¡ç›®
        å‚æ•°ï¼šBeautifulSoupè§£æå‡ºçš„å•ä¸ªç”µå½±æ¡ç›®
        è¿”å›ï¼šåŒ…å«ç”µå½±ä¿¡æ¯çš„å­—å…¸
        """
        global re  # å£°æ˜reä¸ºå…¨å±€å˜é‡ï¼Œå› ä¸ºå‡½æ•°å†…éƒ¨éœ€è¦å¯¼å…¥reæ¨¡å—

        # åˆå§‹åŒ–ç”µå½±ä¿¡æ¯å­—å…¸ï¼Œè®¾ç½®é»˜è®¤å€¼
        movie = {
            'rank': 0,  # æ’å
            'title': 'æœªçŸ¥æ ‡é¢˜',  # ç”µå½±æ ‡é¢˜
            'rating': 0.0,  # è¯„åˆ†
            'votes': 0,  # è¯„ä»·äººæ•°
            'director': 'æœªçŸ¥å¯¼æ¼”',  # å¯¼æ¼”
            'year': 0,  # ä¸Šæ˜ å¹´ä»½
            'country': 'æœªçŸ¥å›½å®¶/åœ°åŒº',  # å›½å®¶/åœ°åŒº
            'tags': '',  # æ ‡ç­¾
            'quote': '',  # ç»å…¸å°è¯/ç®€ä»‹
            'url': '',  # ç”µå½±è¯¦æƒ…é¡µURL
            'image_url': ''  # ç”µå½±å°é¢å›¾ç‰‡URL
        }

        try:
            # 1. è§£ææ’åï¼ˆæœ€ç¨³å®šçš„é€‰æ‹©å™¨ï¼‰
            rank_elem = item.find('em')  # æ’åé€šå¸¸ç”¨<em>æ ‡ç­¾è¡¨ç¤º
            if rank_elem:
                movie['rank'] = int(rank_elem.get_text(strip=True))

            # 2. è§£ææ ‡é¢˜
            title_elem = item.find('span', class_='title')
            if title_elem:
                movie['title'] = title_elem.get_text(strip=True)

            # 3. è§£æè¯„åˆ†ä¸è¯„ä»·äººæ•°
            # 3.1 æå–è¯„åˆ† - ä» property="v:average" çš„å±æ€§ä¸­è·å–
            rating_elem = item.find('span', {'property': 'v:average'})
            if rating_elem:
                try:
                    movie['rating'] = float(rating_elem.get_text(strip=True))
                except ValueError:
                    movie['rating'] = 0.0
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•æ—§çš„ class é€‰æ‹©å™¨
                backup_elem = item.find('span', class_='rating_num')
                if backup_elem:
                    try:
                        movie['rating'] = float(backup_elem.get_text(strip=True))
                    except ValueError:
                        movie['rating'] = 0.0
                else:
                    movie['rating'] = 0.0

            # 3.2 æå–è¯„ä»·äººæ•° - å®ƒåœ¨è¯„åˆ†æ‰€åœ¨çš„divå†…ï¼Œæ˜¯ä¸‹ä¸€ä¸ªspan
            rating_div = rating_elem.parent if rating_elem else None
            movie['votes'] = 0  # é»˜è®¤å€¼
            if rating_div:
                # æ‰¾åˆ°è¿™ä¸ªdivé‡Œæ‰€æœ‰çš„span
                all_spans = rating_div.find_all('span')
                for span in all_spans:
                    text = span.get_text(strip=True)
                    if 'äººè¯„ä»·' in text:
                        # æå–æ•°å­—
                        import re  # åœ¨éœ€è¦æ—¶å¯¼å…¥reæ¨¡å—
                        num_match = re.search(r'(\d+)', text.replace(',', ''))
                        if num_match:
                            movie['votes'] = int(num_match.group(1))
                        break

            # 4. æå–ç®€ä»‹/å°è¯
            quote_candidate = None
            for span in item.find_all('span'):
                txt = span.get_text(strip=True)
                # å°è¯é€šå¸¸è¾ƒçŸ­ï¼Œä¸”åŒ…å«æ ‡ç‚¹
                if 50 > len(txt) > 4 and ('ã€‚' in txt or 'ï¼Œ' in txt):
                    quote_candidate = txt
                    break
            movie['quote'] = quote_candidate if quote_candidate else ''

            # 5. æå–é“¾æ¥å’Œå›¾ç‰‡
            link_elem = item.find('a')
            if link_elem and 'href' in link_elem.attrs:
                movie['url'] = link_elem['href']

            img_elem = item.find('img')
            if img_elem and 'src' in img_elem.attrs:
                movie['image_url'] = img_elem['src']

            # 6. æå–å¯¼æ¼”ã€å¹´ä»½ã€å›½å®¶ç­‰ä¿¡æ¯ï¼ˆä»bdä¿¡æ¯å—è§£æï¼‰
            bd_div = item.find('div', class_='bd')
            if bd_div:
                info_text = bd_div.get_text(' ', strip=True)
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ä¿¡æ¯
                # å¯¼æ¼”
                director_match = re.search(r'å¯¼æ¼”:\s*(\S+)', info_text)
                if director_match:
                    movie['director'] = director_match.group(1)
                # å¹´ä»½ï¼ˆå¯»æ‰¾4ä½æ•°å­—ï¼‰
                year_match = re.search(r'\b(19\d{2}|20\d{2})\b', info_text)
                if year_match:
                    movie['year'] = int(year_match.group(1))
                # å›½å®¶ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                if '/' in info_text:
                    parts = [p.strip() for p in info_text.split('/')]
                    if len(parts) > 2:
                        movie['country'] = parts[-2]  # é€šå¸¸å›½å®¶åœ¨å€’æ•°ç¬¬äºŒéƒ¨åˆ†

            # 7. æå–æ ‡ç­¾
            tag_list = []
            for span in item.find_all('span'):
                if 'class' in span.attrs and len(span['class']) == 1:
                    cls = span['class'][0]
                    # æ’é™¤å·²çŸ¥çš„å…¶ä»–ç±»
                    if cls not in ['title', 'rating_num', 'inq', 'playable']:
                        tag_text = span.get_text(strip=True)
                        if tag_text and len(tag_text) < 8:  # æ ‡ç­¾é€šå¸¸è¾ƒçŸ­
                            tag_list.append(tag_text)
            movie['tags'] = ','.join(tag_list[:3])  # æœ€å¤šå–3ä¸ªæ ‡ç­¾

        except Exception as e:
            # å³ä½¿è§£æå‡ºé”™ï¼Œä¹Ÿè¿”å›ä¸€ä¸ªå¸¦æœ‰é»˜è®¤å€¼çš„å®Œæ•´å­—å…¸
            print(f"âš ï¸  è§£æç”µå½±æ¡ç›®æ—¶é‡åˆ°å°é—®é¢˜ï¼ˆä¸å½±å“æ•´ä½“ï¼‰: {e}")

        # 8. æ·»åŠ çˆ¬å–æ—¶é—´æˆ³
        movie['crawl_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        return movie

    def crawl_all_pages(self):
        """
        çˆ¬å–æ‰€æœ‰é¡µé¢æ•°æ®
        è¿”å›ï¼šåŒ…å«æ‰€æœ‰ç”µå½±ä¿¡æ¯çš„åˆ—è¡¨
        """
        all_movies = []
        print("ğŸ¬ å¼€å§‹çˆ¬å–è±†ç“£ç”µå½±Top250...")

        for page in range(Config.MAX_PAGES):
            start = page * 25  # æ¯é¡µ25éƒ¨ç”µå½±
            print(f"  æ­£åœ¨çˆ¬å–ç¬¬ {page + 1} é¡µ (start={start})...")

            html = self.fetch_page(start)
            if not html:
                continue  # å¦‚æœè·å–é¡µé¢å¤±è´¥ï¼Œè·³è¿‡å½“å‰é¡µ

            soup = BeautifulSoup(html, 'lxml')  # ä½¿ç”¨lxmlè§£æå™¨è§£æHTML
            items = soup.find_all('div', class_='item')  # æ‰¾åˆ°æ‰€æœ‰ç”µå½±æ¡ç›®

            for item in items:
                movie_data = self.parse_movie_item(item)
                if movie_data:
                    all_movies.append(movie_data)

            print(f"  âœ“ ç¬¬ {page + 1} é¡µå®Œæˆï¼Œç´¯è®¡ {len(all_movies)} éƒ¨ç”µå½±")

            if len(items) < 25:  # æœ€åä¸€é¡µå¯èƒ½ä¸è¶³25éƒ¨
                break

        print(f"âœ… çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_movies)} éƒ¨ç”µå½±æ•°æ®")
        return all_movies
# =================================================

# ==================== æ•°æ®å¤„ç†æ¨¡å— ====================
class DataProcessor:
    """æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†ç±»"""

    @staticmethod
    def clean_data(movies_df):
        """
        æ•°æ®æ¸…æ´—ï¼ˆå®‰å…¨ç‰ˆï¼‰
        å‚æ•°ï¼šåŒ…å«åŸå§‹ç”µå½±æ•°æ®çš„DataFrame
        è¿”å›ï¼šæ¸…æ´—åçš„DataFrame
        """
        print("ğŸ§¹ æ­£åœ¨è¿›è¡Œæ•°æ®æ¸…æ´—...")

        # 1. ç¡®ä¿DataFrameåŒ…å«æ‰€æœ‰å¿…éœ€çš„åˆ—
        required_columns = ['director', 'country', 'quote', 'tags', 'rating', 'votes']
        for col in required_columns:
            if col not in movies_df.columns:
                print(f"  âš ï¸  è­¦å‘Šï¼šåˆ— '{col}' ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºå¹¶å¡«å……é»˜è®¤å€¼")
                if col == 'director':
                    movies_df[col] = 'æœªçŸ¥å¯¼æ¼”'
                elif col == 'country':
                    movies_df[col] = 'æœªçŸ¥å›½å®¶/åœ°åŒº'
                elif col == 'quote':
                    movies_df[col] = ''
                elif col == 'tags':
                    movies_df[col] = ''
                elif col == 'rating':
                    movies_df[col] = 0.0
                elif col == 'votes':
                    movies_df[col] = 0

        # 2. ç§»é™¤å®Œå…¨é‡å¤çš„æ•°æ®è¡Œ
        initial_count = len(movies_df)
        movies_df.drop_duplicates(subset=['title', 'rating', 'director'], keep='first', inplace=True)

        # 3. å¤„ç†ç¼ºå¤±å€¼ï¼ˆç°åœ¨è¿™äº›åˆ—è‚¯å®šå­˜åœ¨äº†ï¼‰
        movies_df['director'] = movies_df['director'].fillna('æœªçŸ¥å¯¼æ¼”')
        movies_df['country'] = movies_df['country'].fillna('æœªçŸ¥å›½å®¶/åœ°åŒº')
        movies_df['quote'] = movies_df['quote'].fillna('')
        movies_df['tags'] = movies_df['tags'].fillna('')

        # 4. åˆ›å»ºè¡ç”Ÿç‰¹å¾
        # è¯„åˆ†åˆ†ç±»
        movies_df['rating_category'] = pd.cut(
            movies_df['rating'],
            bins=[0, 7.0, 8.0, 8.5, 9.0, 10],
            labels=['ä¸€èˆ¬(<7)', 'è‰¯å¥½(7-8)', 'ä¼˜ç§€(8-8.5)', 'ç»å…¸(8.5-9)', 'ç¥ä½œ(>9)']
        )

        # è®¡ç®—è¯„ä»·çƒ­åº¦ï¼ˆå½’ä¸€åŒ–åˆ°0-100ï¼‰
        if movies_df['votes'].max() > 0:
            movies_df['popularity'] = (movies_df['votes'] / movies_df['votes'].max() * 100).round(2)
        else:
            movies_df['popularity'] = 0.0

        print(f"  âœ“ æ•°æ®æ¸…æ´—å®Œæˆï¼Œç§»é™¤ {initial_count - len(movies_df)} æ¡é‡å¤è®°å½•")
        print(f"  âœ“ æœ€ç»ˆæ•°æ®å½¢çŠ¶: {movies_df.shape[0]} è¡Œ Ã— {movies_df.shape[1]} åˆ—")
        return movies_df

    @staticmethod
    def extract_tags_statistics(movies_df):
        """
        æå–æ ‡ç­¾ç»Ÿè®¡ä¿¡æ¯
        å‚æ•°ï¼šç”µå½±DataFrame
        è¿”å›ï¼šæ ‡ç­¾ç»Ÿè®¡DataFrame
        """
        all_tags = []
        for tags in movies_df['tags'].dropna():
            if tags:
                all_tags.extend([tag.strip() for tag in tags.split(',') if tag.strip()])

        from collections import Counter
        tag_counts = Counter(all_tags)  # ç»Ÿè®¡æ¯ä¸ªæ ‡ç­¾å‡ºç°çš„æ¬¡æ•°
        return pd.DataFrame(
            tag_counts.most_common(20),  # å–å‰20ä¸ªæœ€å¸¸è§çš„æ ‡ç­¾
            columns=['tag', 'count']
        )
# =================================================

# ==================== æ•°æ®å­˜å‚¨æ¨¡å— ====================
class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†ç±»ï¼Œè´Ÿè´£SQLiteæ•°æ®åº“æ“ä½œ"""

    def __init__(self, db_name=Config.DB_NAME):
        """åˆå§‹åŒ–ï¼Œè¿æ¥æ•°æ®åº“å¹¶åˆ›å»ºè¡¨"""
        self.conn = sqlite3.connect(db_name)  # è¿æ¥SQLiteæ•°æ®åº“
        self.create_tables()  # åˆ›å»ºæ•°æ®è¡¨

    def create_tables(self):
        """åˆ›å»ºæ•°æ®è¡¨"""
        cursor = self.conn.cursor()

        # ä¸»ç”µå½±è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS movies (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                rank INTEGER,
                title TEXT NOT NULL,
                rating REAL,
                votes INTEGER,
                director TEXT,
                year INTEGER,
                country TEXT,
                tags TEXT,
                `quote` TEXT,  -- è¿™é‡Œä¿®æ”¹ï¼šç”¨åå¼•å·åŒ…è£¹ï¼ˆquoteæ˜¯SQLå…³é”®å­—ï¼‰
                url TEXT,
                image_url TEXT,
                rating_category TEXT,
                popularity REAL,
                crawl_time TEXT,
                UNIQUE(title)  -- æ ‡é¢˜å”¯ä¸€ï¼Œé¿å…é‡å¤
            )
        ''')

        # æ ‡ç­¾ç»Ÿè®¡è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS tags_stats (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tag TEXT UNIQUE,
                count INTEGER,
                update_time TEXT
            )
        ''')

        # åˆ†æç»“æœè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analysis_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                metric_name TEXT,
                metric_value REAL,
                description TEXT,
                update_time TEXT
            )
        ''')

        self.conn.commit()  # æäº¤äº‹åŠ¡

    def save_movies(self, movies_df):
        """
        ä¿å­˜ç”µå½±æ•°æ®åˆ°æ•°æ®åº“
        å‚æ•°ï¼šæ¸…æ´—åçš„ç”µå½±DataFrame
        """
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“...")

        try:
            # å°†DataFrameä¿å­˜åˆ°moviesè¡¨ï¼Œå¦‚æœè¡¨å­˜åœ¨åˆ™æ›¿æ¢
            movies_df.to_sql('movies', self.conn, if_exists='replace', index=False)
            print(f"  âœ“ æˆåŠŸä¿å­˜ {len(movies_df)} æ¡ç”µå½±è®°å½•")

            # ä¿å­˜æ ‡ç­¾ç»Ÿè®¡
            tag_stats = DataProcessor.extract_tags_statistics(movies_df)
            tag_stats['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            tag_stats.to_sql('tags_stats', self.conn, if_exists='replace', index=False)

        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")

    def get_analysis_data(self):
        """ä»æ•°æ®åº“è·å–åˆ†ææ•°æ®"""
        return pd.read_sql_query("SELECT * FROM movies", self.conn)

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.conn.close()
# =================================================

# ==================== å¯è§†åŒ–æ¨¡å— ====================
class DataVisualizer:
    """æ•°æ®å¯è§†åŒ–ç±»ï¼Œè´Ÿè´£ç”Ÿæˆå„ç§å›¾è¡¨"""

    def __init__(self, movies_df):
        """åˆå§‹åŒ–ï¼Œè®¾ç½®å›¾è¡¨æ ·å¼å’Œé¢œè‰²"""
        self.df = movies_df  # ç”µå½±æ•°æ®DataFrame
        plt.style.use('seaborn-v0_8-darkgrid')  # ä½¿ç”¨seabornæ ·å¼
        # æ˜ç¡®æŒ‡å®šä¸ºPythonåˆ—è¡¨ï¼Œé¿å…ç±»å‹æ¨æ–­é—®é¢˜
        self.colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']  # é…è‰²æ–¹æ¡ˆ
        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'KaiTi']  # ä¸­æ–‡å­—ä½“
        plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

    def plot_rating_distribution(self, save_path='rating_distribution.png'):
        """
        ç»˜åˆ¶è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾
        å‚æ•°ï¼šä¿å­˜è·¯å¾„
        """
        plt.figure(figsize=(12, 6))  # åˆ›å»ºå›¾å½¢ï¼Œè®¾ç½®å°ºå¯¸

        plt.subplot(1, 2, 1)  # ç¬¬ä¸€ä¸ªå­å›¾ï¼ˆ1è¡Œ2åˆ—çš„ç¬¬1ä¸ªï¼‰
        # ç»˜åˆ¶ç›´æ–¹å›¾
        n, bins, patches = plt.hist(self.df['rating'], bins=20, edgecolor='black', alpha=0.7, color=self.colors[0])
        plt.title('è±†ç“£Top250è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾', fontsize=14, fontweight='bold')
        plt.xlabel('è¯„åˆ†', fontsize=12)
        plt.ylabel('ç”µå½±æ•°é‡', fontsize=12)
        plt.grid(True, alpha=0.3)  # æ˜¾ç¤ºç½‘æ ¼

        # æ·»åŠ æ•°æ®æ ‡ç­¾ï¼ˆåœ¨æŸ±å­é¡¶éƒ¨æ˜¾ç¤ºæ•°é‡ï¼‰
        for i in range(len(n)):
            if n[i] > 0:
                plt.text(float(bins[i]) + (float(bins[i+1]) - float(bins[i]))/2, float(n[i]) + 0.5,
                         str(int(n[i])), ha='center', va='bottom', fontsize=9)

        plt.subplot(1, 2, 2)  # ç¬¬äºŒä¸ªå­å›¾
        rating_counts = self.df['rating_category'].value_counts().sort_index()
        bars = plt.bar(rating_counts.index, rating_counts.values, color=self.colors[1:])
        plt.xlabel('è¯„åˆ†ç­‰çº§', fontsize=12)
        plt.ylabel('ç”µå½±æ•°é‡', fontsize=12)
        plt.title('è¯„åˆ†ç­‰çº§åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xticks(rotation=45)  # xè½´æ ‡ç­¾æ—‹è½¬45åº¦

        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width() / 2., height + 0.5,
                     f'{int(height)}', ha='center', va='bottom', fontsize=10)

        plt.tight_layout()  # è‡ªåŠ¨è°ƒæ•´å­å›¾å‚æ•°
        plt.savefig(save_path, dpi=150, bbox_inches='tight')  # ä¿å­˜å›¾å½¢
        print(f"  âœ“ è¯„åˆ†åˆ†å¸ƒå›¾å·²ä¿å­˜ä¸º {save_path}")

    def plot_scatter_rating_votes(self, save_path='rating_votes_scatter.png'):
        """
        ç»˜åˆ¶è¯„åˆ†ä¸è¯„ä»·äººæ•°æ•£ç‚¹å›¾ï¼ˆæ°”æ³¡å›¾ï¼‰
        æ°”æ³¡å¤§å°è¡¨ç¤ºçƒ­åº¦ï¼Œé¢œè‰²è¡¨ç¤ºå¹´ä»½
        """
        plt.figure(figsize=(10, 6))

        # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼Œé¢œè‰²è¡¨ç¤ºå¹´ä»½ï¼Œå¤§å°è¡¨ç¤ºçƒ­åº¦
        scatter = plt.scatter(self.df['rating'], self.df['votes'],
                              c=self.df['year'], cmap='viridis',
                              s=self.df['popularity'], alpha=0.6, edgecolors='w', linewidth=0.5)

        plt.colorbar(scatter, label='ä¸Šæ˜ å¹´ä»½')  # æ·»åŠ é¢œè‰²æ¡
        plt.xlabel('è¯„åˆ†', fontsize=12)
        plt.ylabel('è¯„ä»·äººæ•°', fontsize=12)
        plt.title('è¯„åˆ† vs è¯„ä»·äººæ•° (æ°”æ³¡å¤§å°=çƒ­åº¦)', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)

        # æ·»åŠ å…³é”®ç‚¹æ ‡æ³¨ï¼ˆè¯„åˆ†æœ€é«˜çš„å‡ éƒ¨ï¼‰
        top_movies = self.df.nlargest(5, 'rating')  # å–è¯„åˆ†æœ€é«˜çš„5éƒ¨ç”µå½±
        for _, movie in top_movies.iterrows():
            plt.annotate(movie['title'][:10] + '...',  # åªæ˜¾ç¤ºå‰10ä¸ªå­—ç¬¦
                         xy=(movie['rating'], movie['votes']),  # æ ‡æ³¨ç‚¹åæ ‡
                         xytext=(5, 5), textcoords='offset points',  # æ–‡æœ¬åç§»
                         fontsize=9, arrowprops=dict(arrowstyle='->', alpha=0.5))

        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"  âœ“ æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º {save_path}")

    def plot_yearly_trend(self, save_path='yearly_trend.png'):
        """ç»˜åˆ¶å¹´åº¦è¶‹åŠ¿åˆ†æå›¾"""
        plt.figure(figsize=(12, 5))

        # æŒ‰å¹´ä»½ç»Ÿè®¡ç”µå½±æ•°é‡
        yearly_counts = self.df.groupby('year').size()

        plt.subplot(1, 2, 1)  # ç¬¬ä¸€ä¸ªå­å›¾ï¼šå¹´ä»½åˆ†å¸ƒæŠ˜çº¿å›¾
        plt.plot(yearly_counts.index, yearly_counts.values,
                 marker='o', linewidth=2, markersize=6, color=self.colors[2])
        plt.fill_between(yearly_counts.index, yearly_counts.values, alpha=0.3, color=self.colors[2])  # å¡«å……åŒºåŸŸ
        plt.xlabel('å¹´ä»½', fontsize=12)
        plt.ylabel('ç”µå½±æ•°é‡', fontsize=12)
        plt.title('Top250ç”µå½±å¹´ä»½åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)

        # æŒ‰å¹´ä»½å¹³å‡è¯„åˆ†
        plt.subplot(1, 2, 2)  # ç¬¬äºŒä¸ªå­å›¾ï¼šå„å¹´ä»½å¹³å‡è¯„åˆ†æŸ±çŠ¶å›¾
        yearly_rating = self.df.groupby('year')['rating'].mean()
        plt.bar(yearly_rating.index, yearly_rating.values, color=self.colors[3], alpha=0.7)
        plt.xlabel('å¹´ä»½', fontsize=12)
        plt.ylabel('å¹³å‡è¯„åˆ†', fontsize=12)
        plt.title('å„å¹´ä»½ç”µå½±å¹³å‡è¯„åˆ†', fontsize=14, fontweight='bold')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"  âœ“ å¹´åº¦è¶‹åŠ¿å›¾å·²ä¿å­˜ä¸º {save_path}")

    def create_wordcloud(self, save_path='wordcloud.png'):
        """ç”Ÿæˆæ ‡ç­¾è¯äº‘å›¾"""
        all_text = ' '.join(self.df['tags'].dropna().tolist())  # å°†æ‰€æœ‰æ ‡ç­¾åˆå¹¶ä¸ºå­—ç¬¦ä¸²
        if not all_text:
            print("âš ï¸  æ²¡æœ‰æ ‡ç­¾æ•°æ®å¯ç”¨äºç”Ÿæˆè¯äº‘")
            return

        # ä½¿ç”¨ä¸­æ–‡åœç”¨è¯
        stopwords = set(STOPWORDS)
        stopwords.update(['ç”µå½±', 'å½±ç‰‡', 'å¯¼æ¼”'])  # æ·»åŠ è‡ªå®šä¹‰åœç”¨è¯

        wordcloud = WordCloud(
            font_path='C:/Windows/Fonts/simhei.ttf',  # Windowsç³»ç»Ÿé»‘ä½“å­—ä½“è·¯å¾„
            width=800, height=400,
            background_color='white',
            max_words=100,  # æœ€å¤šæ˜¾ç¤º100ä¸ªè¯
            stopwords=stopwords,  # åœç”¨è¯
            contour_width=1,  # è½®å»“å®½åº¦
            contour_color='steelblue',  # è½®å»“é¢œè‰²
            colormap='viridis'  # é¢œè‰²æ˜ å°„
        ).generate(all_text)

        plt.figure(figsize=(12, 6))
        plt.imshow(wordcloud, interpolation='bilinear')  # æ˜¾ç¤ºè¯äº‘
        plt.axis('off')  # å…³é—­åæ ‡è½´
        plt.title('è±†ç“£Top250ç”µå½±æ ‡ç­¾è¯äº‘', fontsize=16, fontweight='bold', pad=20)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"  âœ“ è¯äº‘å›¾å·²ä¿å­˜ä¸º {save_path}")

    def create_dashboard(self):
        """åˆ›å»ºç»¼åˆä»ªè¡¨æ¿ï¼ˆåŒ…å«å¤šä¸ªå­å›¾ï¼‰"""
        print("ğŸ“Š ç”Ÿæˆæ•°æ®åˆ†æä»ªè¡¨æ¿...")

        # åˆ›å»º2x2çš„ä»ªè¡¨æ¿
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('è±†ç“£ç”µå½±Top250æ•°æ®åˆ†æä»ªè¡¨æ¿', fontsize=18, fontweight='bold', y=0.98)

        # 1. è¯„åˆ†åˆ†å¸ƒç®±çº¿å›¾
        axes[0, 0].boxplot(self.df['rating'], vert=False, patch_artist=True,
                           boxprops=dict(facecolor=self.colors[0], alpha=0.7))
        axes[0, 0].set_xlabel('è¯„åˆ†')
        axes[0, 0].set_title('è¯„åˆ†åˆ†å¸ƒç®±çº¿å›¾', fontweight='bold')
        axes[0, 0].grid(True, alpha=0.3)

        # 2. è¯„åˆ†å‰åç”µå½±æ°´å¹³æŸ±çŠ¶å›¾
        top10 = self.df.nlargest(10, 'rating')[['title', 'rating']]
        y_pos = range(len(top10))
        axes[0, 1].barh(y_pos, top10['rating'], color=self.colors[1])
        axes[0, 1].set_yticks(y_pos)
        # æ ‡é¢˜å¤ªé•¿æ—¶æˆªæ–­æ˜¾ç¤º
        axes[0, 1].set_yticklabels([t[:15] + '...' if len(t) > 15 else t for t in top10['title']])
        axes[0, 1].set_xlabel('è¯„åˆ†')
        axes[0, 1].set_title('è¯„åˆ†Top10ç”µå½±', fontweight='bold')
        axes[0, 1].invert_yaxis()  # åè½¬yè½´ï¼Œä½¿æœ€é«˜è¯„åˆ†åœ¨æœ€ä¸Šé¢

        # 3. å›½å®¶åˆ†å¸ƒé¥¼å›¾ï¼ˆå‰10ï¼‰
        country_counts = self.df['country'].str.split('/').explode().str.strip().value_counts().head(10)
        axes[1, 0].pie(country_counts.values, labels=country_counts.index,
                       autopct='%1.1f%%', colors=self.colors, startangle=90)
        axes[1, 0].set_title('ç”µå½±å›½å®¶/åœ°åŒºåˆ†å¸ƒ(Top10)', fontweight='bold')

        # 4. è¯„ä»·äººæ•°åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆå¯¹æ•°å°ºåº¦ï¼‰
        axes[1, 1].hist(np.log10(self.df['votes'] + 1), bins=15,
                        edgecolor='black', alpha=0.7, color=self.colors[3])
        axes[1, 1].set_xlabel('è¯„ä»·äººæ•°(å¯¹æ•°å°ºåº¦)')
        axes[1, 1].set_ylabel('ç”µå½±æ•°é‡')
        axes[1, 1].set_title('è¯„ä»·äººæ•°åˆ†å¸ƒ(å¯¹æ•°è½¬æ¢)', fontweight='bold')
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()
        dashboard_path = 'analysis_dashboard.png'
        plt.savefig(dashboard_path, dpi=150, bbox_inches='tight')
        print(f"  âœ“ ç»¼åˆä»ªè¡¨æ¿å·²ä¿å­˜ä¸º {dashboard_path}")
# =================================================

# ==================== åˆ†ææŠ¥å‘Šæ¨¡å— ====================
class AnalysisReporter:
    """ç”Ÿæˆåˆ†ææŠ¥å‘Šç±»"""

    @staticmethod
    def generate_report(movies_df):
        """ç”Ÿæˆæ–‡æœ¬åˆ†ææŠ¥å‘Š"""
        report = ["è±†ç“£ç”µå½±Top250æ¦œå• **å‰50åï¼ˆå‰20%ï¼‰** åˆ†ææŠ¥å‘Š", "=" * 60,
                  f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                  f"åˆ†æèŒƒå›´: Top250æ¦œå•çš„å‰ {len(movies_df)} éƒ¨ç”µå½±ï¼ˆå‰{len(movies_df) / 250 * 100:.0f}%ï¼‰",
                  f"æ•°æ®æ€»é‡: {len(movies_df)} éƒ¨ç”µå½±", "-" * 60, "ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:",
                  f"  å¹³å‡è¯„åˆ†: {movies_df['rating'].mean():.2f}", f"  è¯„åˆ†ä¸­ä½æ•°: {movies_df['rating'].median():.2f}",
                  f"  æœ€é«˜è¯„åˆ†: {movies_df['rating'].max():.2f}", f"  æœ€ä½è¯„åˆ†: {movies_df['rating'].min():.2f}"]

        # åŸºæœ¬ç»Ÿè®¡
        total_votes = movies_df['votes'].sum()
        avg_votes = movies_df['votes'].mean()
        median_votes = movies_df['votes'].median()
        report.append(f"  è¯„ä»·äººæ•°æ€»å’Œ (å‰{len(movies_df)}éƒ¨): {total_votes:,}")
        report.append(f"  å¹³å‡æ¯éƒ¨è¯„ä»·äººæ•°: {avg_votes:,.0f}")
        report.append(f"  è¯„ä»·äººæ•°ä¸­ä½æ•°: {median_votes:,.0f}")

        # è¯„åˆ†åˆ†å¸ƒ
        report.append("\nğŸ† è¯„åˆ†åˆ†å¸ƒ:")
        rating_dist = movies_df['rating_category'].value_counts().sort_index()
        for category, count in rating_dist.items():
            percentage = (count / len(movies_df)) * 100
            report.append(f"  {category}: {count} éƒ¨ ({percentage:.1f}%)")

        # å¹´ä»£åˆ†æ
        report.append("\nğŸ“… å¹´ä»£åˆ†æ:")
        decade_counts = (movies_df['year'] // 10 * 10).value_counts().sort_index()
        for decade, count in decade_counts.items():
            if decade > 1900:
                report.append(f"  {decade}s: {count} éƒ¨")

        # å¯¼æ¼”åˆ†æ
        report.append("\nğŸ¬ å¯¼æ¼”ä½œå“æ•°é‡Top5:")
        director_counts = movies_df['director'].value_counts().head(5)
        for director, count in director_counts.items():
            report.append(f"  {director}: {count} éƒ¨")

        # çƒ­é—¨æ ‡ç­¾
        all_tags = []
        for tags in movies_df['tags'].dropna():
            if tags:
                all_tags.extend([tag.strip() for tag in tags.split(',') if tag.strip()])

        from collections import Counter
        tag_counts = Counter(all_tags)
        report.append("\nğŸ·ï¸  çƒ­é—¨æ ‡ç­¾Top10:")
        for tag, count in tag_counts.most_common(10):
            report.append(f"  {tag}: {count} æ¬¡")

        report.append("=" * 60)

        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_text = '\n'.join(report)
        with open('analysis_report.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)

        print("ğŸ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜ä¸º analysis_report.txt")
        print("\n" + report_text[:500] + "...\n")  # æ‰“å°æŠ¥å‘Šå¼€å¤´éƒ¨åˆ†
# =================================================

# ==================== ä¸»ç¨‹åº ====================
def main():
    """ä¸»ç¨‹åºæµç¨‹"""
    print("=" * 60)
    print("è±†ç“£ç”µå½±Top250æ•°æ®åˆ†æç³»ç»Ÿ v2.0")
    print("=" * 60)

    # 1. çˆ¬å–æ•°æ®
    spider = DoubanSpider()
    movies_data = spider.crawl_all_pages()

    if not movies_data:
        print("âŒ æœªè·å–åˆ°æ•°æ®ï¼Œç¨‹åºé€€å‡º")
        return

    # 2. è½¬æ¢ä¸ºDataFrameå¹¶è¿›è¡Œæ•°æ®å¤„ç†
    df = pd.DataFrame(movies_data)
    processor = DataProcessor()
    df_cleaned = processor.clean_data(df)

    # æ–°å¢ï¼šæ•°æ®å®Œæ•´æ€§å¿«é€Ÿæ£€æŸ¥
    print("\nğŸ” æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ï¼š")
    print(f"æ€»è®°å½•æ•°: {len(df_cleaned)}")
    print(f"è¯„åˆ†ç¼ºå¤±æ•°: {df_cleaned['rating'].isnull().sum()}")
    print(f"è¯„ä»·äººæ•°ç¼ºå¤±æ•°: {df_cleaned['votes'].isnull().sum()}")
    print(f"è¯„åˆ†èŒƒå›´: {df_cleaned['rating'].min():.2f} - {df_cleaned['rating'].max():.2f}")
    print(f"è¯„ä»·äººæ•°æ€»å’Œï¼ˆåŸå§‹ï¼‰: {df_cleaned['votes'].sum():,}")

    # 3. ä¿å­˜åˆ°æ•°æ®åº“
    db_manager = DatabaseManager()
    db_manager.save_movies(df_cleaned)

    # 4. ç”Ÿæˆåˆ†ææŠ¥å‘Š
    reporter = AnalysisReporter()
    reporter.generate_report(df_cleaned)

    # 5. æ•°æ®å¯è§†åŒ–
    visualizer = DataVisualizer(df_cleaned)
    visualizer.plot_rating_distribution()
    visualizer.plot_scatter_rating_votes()
    visualizer.plot_yearly_trend()
    visualizer.create_wordcloud()
    visualizer.create_dashboard()

    # 6. å…³é—­æ•°æ®åº“è¿æ¥
    db_manager.close()

    print("=" * 60)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - douban_movies.db (SQLiteæ•°æ®åº“)")
    print("  - analysis_report.txt (åˆ†ææŠ¥å‘Š)")
    print("  - rating_distribution.png (è¯„åˆ†åˆ†å¸ƒ)")
    print("  - rating_votes_scatter.png (æ•£ç‚¹å›¾)")
    print("  - yearly_trend.png (å¹´åº¦è¶‹åŠ¿)")
    print("  - wordcloud.png (è¯äº‘å›¾)")
    print("  - analysis_dashboard.png (ç»¼åˆä»ªè¡¨æ¿)")
    print("=" * 60)
    print("é¡¹ç›®åˆ¶ä½œäºº:")
    print("è®¡23-2")
    print("åˆ˜æ–‡æ˜Š")
    print("23101020204")
    print("=" * 60)
# =================================================

# ç¨‹åºå…¥å£
if __name__ == '__main__':
    main()